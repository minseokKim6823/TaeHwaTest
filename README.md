# íƒœí™”ì´ë…¸ë² ì´ì…˜ ê³¼ì œí…ŒìŠ¤íŠ¸(paddleOCRì„ ì´ìš©í•œ ê¸€ì ì¸ì‹)

## ğŸ”¹ ì„¸íŒ… ë°©ë²•

```bash
pip install paddlepaddle
```

```python
import paddle
print("PaddlePaddle ì„¤ì¹˜ ì™„ë£Œ!")
```

# ë°©ë²•ë¡ 1 - ì‚¬ì§„ì„ ìµœì í™” í•´ë³´ì!

ìƒê°í•œ ì´ìœ  - paddlepaddleì„ ì‚¬ìš©í•´ë³¸ ê²°ê³¼ **ì„±ëŠ¥ì´ í›Œë¥­**í–ˆë‹¤.
ë”°ë¼ì„œ, ì‚¬ì§„ì˜ ëª…ì•” ëŒ€ë¹„ë¥¼ í™•ì—°í•˜ê²Œ ê°€ì ¸ê°„ë‹¤ë©´ ê¸€ìë¥¼ ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  íŒë‹¨ì„ í–ˆë‹¤.   

### 1. ì²« ë²ˆì§¸ ì‹¤í–‰ ì½”ë“œì™€ jpg íŒŒì¼

```python
from paddleocr import PaddleOCR

# OCR ê°ì²´ ìƒì„± (í•œêµ­ì–´ ì„¤ì •)
ocr = PaddleOCR(lang="korean")

# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
img_path = 'C:/Users/alstj/Desktop/hello.jpg'

# OCR ìˆ˜í–‰
result = ocr.ocr(img_path)

# ì²« ë²ˆì§¸ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
result = result[0]

# ì¸ì‹ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥
for line in result:
    print(line[1][0])  
```

![image](https://github.com/user-attachments/assets/a5ea18ff-5051-460f-9421-41bf5bf3cf85)<br>
**hello.jpg**
<br><br><br><br>
![image](https://github.com/user-attachments/assets/1f246389-f5f2-40b0-b688-d0c5a1c930a0)<br>
**ì‹¤í–‰ê²°ê³¼**
<br><br>
â€˜ì•ˆë…•â€™ì´ ì•„ë‹Œ â€˜ì•ˆí˜•â€™ì´ ë‚˜ì˜´â€¦.

### 2. ë‘ ë²ˆì§¸ ì‹¤í–‰ ì½”ë“œì™€ jpg íŒŒì¼(ë™ì¼í•œ jpg íŒŒì¼ë¡œ ì‹œë„ í–ˆìŠµë‹ˆë‹¤.)

ì²«ë²ˆì§¸ ì‹œë„ê°€ ì‹¤íŒ¨í•˜ì—¬ ì›¹ì„œí•‘ì„ í†µí•´ ì•Œì•„ë³¸ ê²°ê³¼, ì¸ì‹ëœ í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ì„ê³„ê°’ì´ ë‚®ì•„ì„œ ì˜¤ì¸ì‹ì´ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ê³  í•œë‹¤.

ë”°ë¼ì„œ OCR ê°ì²´ ìƒì„±ì‹œ  drop_score=0.7ì„ ì¶”ê°€í•˜ì—¬ ì‹ ë¢°ë„ê°€ 0.7ì´ìƒì¸ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ë„ë¡ í–ˆë‹¤.

```python
from paddleocr import PaddleOCR

# OCR ê°ì²´ ìƒì„± (í•œêµ­ì–´ ì„¤ì •)
ocr = PaddleOCR(lang="korean", drop_score=0.7)

# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
img_path = 'C:/Users/alstj/Desktop/hello.jpg'

# OCR ìˆ˜í–‰
result = ocr.ocr(img_path)

# ì²« ë²ˆì§¸ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
result = result[0]

# ì¸ì‹ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥
for line in result:
    print(line[1][0])  
```

![image](https://github.com/user-attachments/assets/c4130cb9-bcf6-4c8a-bd77-1618a11a02bf)


ì•ˆíƒ€ê¹ê²Œë„ ê²°ê³¼ê°’ì€ ë³€í™”ê°€ ì—†ì—ˆë‹¤.ğŸ˜‚

### 3. ì„¸ ë²ˆì§¸ ì‹œë„ : **GrayScale ì ìš©í•˜ê¸°**

PaddleOCRì—ì„œ **GrayScale**ì„ ì¶”ê°€í•´ì„œ OCR ì„±ëŠ¥ì„ ìµœì í™” í•´ë³´ì•˜ë‹¤.

<aside>
ğŸ’¡

### GrayScaleì´ë€?

**Grayscale**(ê·¸ë ˆì´ìŠ¤ì¼€ì¼)ì€ í‘ë°± ì´ë¯¸ì§€ë¥¼ ì˜ë¯¸í•œë‹¤.

ì¦‰, ìƒ‰ìƒ(ì»¬ëŸ¬) ì •ë³´ë¥¼ ì œê±°í•˜ê³  ë°ê¸°(intensity)ë§Œ ë‚¨ê¸´ ì´ë¯¸ì§€.

ex. í‘ë°± TV, ìŠ¤ìºë„ˆë¡œ ìŠ¤ìº”í•œ ë¬¸ì„œ 

</aside>

![image](https://github.com/user-attachments/assets/334846d6-f152-4d55-b574-b32d79224d03)


```python
import cv2
from paddleocr import PaddleOCR

# OCR ê°ì²´ ìƒì„± (í•œêµ­ì–´ ì„¤ì •)
ocr = PaddleOCR(lang="korean", drop_score=0.7)

#ì´ë¯¸ì§€ê²½ë¡œ
img_path = 'C:/Users/alstj/Desktop/hello.jpg'

# ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

# ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì €ì¥
gray_img_path = 'C:/Users/alstj/Desktop/gray_hello.jpg'
cv2.imwrite(gray_img_path, img)

result = ocr.ocr(gray_img_path)

result = result[0]

for line in result:
    print(line[1][0])
```

 

![image](https://github.com/user-attachments/assets/f904e6bb-75b0-4780-b187-ebe1b964dc14)<br>
GrayScale ì „
<br><br><br><br>
![image](https://github.com/user-attachments/assets/cda0127a-2160-44b5-a171-4f3c7ec64166)<br>
GrayScale ì§„í–‰ í›„(íŒŒì¼ëª…ì´ gray_helloì„) 
<br><br><br><br>
![image](https://github.com/user-attachments/assets/06b00643-55fb-4405-9146-b7bb28e4f0e7)<br>
**GrayScale**ì„ ë°˜ì˜í•´ë³¸ ê²°ê³¼ ì•ˆë…•ì€ ì•ˆì˜ìœ¼ë¡œ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤

### 4. ë„¤ ë²ˆì§¸ ì‹œë„ : ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê¸°

GrayScaleì— ëŒ€í•´ ì¶”ê°€ì ìœ¼ë¡œ ì¡°ì‚¬í•´ë³¸ ê²°ê³¼,  ê²€ì •ìƒ‰,íšŒìƒ‰,í°ìƒ‰ ì„¸ ìƒ‰ê¹”ì¤‘ í•˜ë‚˜ë¡œ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ê³  í°ìƒ‰ê³¼ ê²€ì •ìƒ‰ë§Œìœ¼ë¡œ êµ¬ë¶„ì§€ì–´ ê¸€ìì™€ ë°”íƒ•ì„ í™•ì‹¤í•˜ê²Œ êµ¬ë¶„ì§€ì„ ìˆ˜ìˆë„ë¡ ì„ê³„ê°’ì„ ì¡°ì •í•´ì£¼ëŠ” ì‘ì—…ì„ í•´ë³¸ ê²°ê³¼ 

```python
import cv2
from paddleocr import PaddleOCR

# OCR ê°ì²´ ìƒì„± (í•œêµ­ì–´ ì„¤ì •)
ocr = PaddleOCR(lang="korean", drop_score=0.7)

# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
img_path = 'C:/Users/alstj/Desktop/hello.jpg'

# ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

# í‘ë°±(ë°”ì´ë„ˆë¦¬) ì´ë¯¸ì§€ë¡œ ë³€í™˜: ì„ê³„ê°’ 210 ì´í•˜ -> 0, ì´ˆê³¼ -> 255 ì„ê³„ê°’ì„ ì„ì˜ë¡œ ì¡°ì •í–ˆìŒ
_, binary_img = cv2.threshold(gray_img, 210, 255, cv2.THRESH_BINARY)

# ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (OCRì€ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©)
binary_img_path = 'C:/Users/alstj/Desktop/binary_hello.jpg'
cv2.imwrite(binary_img_path, binary_img)

# OCR ìˆ˜í–‰ (ë³€í™˜ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
result = ocr.ocr(binary_img_path)

# ì²« ë²ˆì§¸ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
result = result[0]

# ì¸ì‹ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥
for line in result:
    print(line[1][0])
```

![image](https://github.com/user-attachments/assets/d8cf8956-9992-4dba-b9a8-6aea42f77aa7)<br>
**ë³€í™˜ ê²°ê³¼**
<br><br><br><br><br><br><br>
![image](https://github.com/user-attachments/assets/5ba15a6d-8ef4-4e8a-a77f-43d5111c8f4c)<br>
**ì¶œë ¥ ê²°ê³¼**

                

ì„±ê³µì ìœ¼ë¡œ ê°’ì´ ì¶œë ¥ëë‹¤!

# ë°©ë²•ë¡ 2 - í•™ìŠµì‹œí‚¤ê¸°

PaddleOCRì„ gitHubë¡œ ë¶€í„° í´ë¡ ì„ ë°›ê³  ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ í–ˆë‹¤.
GPUë¥¼ ì‚¬ìš©í•˜ê¸° ì•Šê³  ì‹¤í–‰ì„ í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµ ë°ì´í„°ì— ë”°ë¼ì„œ í•™ìŠµì‹œê°„ì´ ë‹¬ë¼ì§„ë‹¤.(epoch 50 í•™ìŠµë°ì´í„° 150ê°œ â‡’ 20ì‹œê°„ ì •ë„ ê±¸ë¦¼)

![image](https://github.com/user-attachments/assets/06994a42-dd92-4efb-ac07-c0baabc7613a)


**korean_PP-OCRv3_rec_train.yml**

```java
Global:
  use_gpu: false
  epoch_num: 50  # í•™ìŠµí•  ì´ Epoch ìˆ˜
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_korean  # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
  save_epoch_step: 10  # ëª‡ ë²ˆì˜ Epochë§ˆë‹¤ ëª¨ë¸ì„ ì €ì¥í• ì§€
  eval_batch_step: [0, 5000]  # í‰ê°€í•  Step
  cal_metric_during_train: True
  pretrained_model:
  checkpoints:
  save_inference_dir: ./inference/rec_korean  # ë³€í™˜ëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
  use_visualdl: False  # í•™ìŠµ ê¸°ë¡ ì‹œê°í™” ì—¬ë¶€
  infer_img: dataset/train_images/image1.jpg  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
  character_dict_path: ppocr/utils/dict/korean_dict.txt  #  í•œê¸€ ë¬¸ì ì‚¬ì „ ì¶”ê°€
  use_space_char: False

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine
    learning_rate: 0.001  # í•™ìŠµë¥  (í•„ìš”í•˜ë©´ ì¡°ì •)
  regularizer:
    name: L2
    factor: 0.00004

Architecture:
  model_type: rec
  algorithm: SVTR_LCNet  #  í•™ìŠµ ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ê²Œ ìœ ì§€
  Transform: null
  Backbone:
    name: SVTRNet
    img_size: [128, 640]  #  í•™ìŠµí•  ë•Œ ì…ë ¥ í¬ê¸° (ì¶”ë¡ í•  ë•Œë„ ë§ì¶°ì•¼ í•¨)
    out_channels: 192
    layers: [3, 6, 3]
    hidden_dim: 192
    num_heads: [4, 8, 8]
    mixer: ["Local", "Local", "Local", "Global", "Global", "Global", "Global", "Global", "Global", "Global", "Global", "Global"]
    use_guide: True
  Neck:
    name: SequenceEncoder
    encoder_type: svtr
  Head:
    name: CTCHead
    fc_decay: 4.0e-05

Loss:
  name: CTCLoss

PostProcess:
  name: CTCLabelDecode
Metric:
  name: RecMetric
  main_indicator: acc

Train:
  dataset:
    name: LMDBDataSet
    data_dir: C:/data/lmdb/  # ìƒì„±í•œ LMDB ë°ì´í„°ì…‹ ê²½ë¡œ
    label_file_path: C:/data/label.txt  # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
    transforms:
      - DecodeImage:
          img_mode: BGR
      - CTCLabelEncode:
          max_text_length: 25
      - RecResizeImg:
          image_shape: [3, 128, 640]  # í•™ìŠµí•  ë•Œ í¬ê¸° (ì¶”ë¡ í•  ë•Œë„ ë™ì¼í•´ì•¼ í•¨)
      - KeepKeys:
          keep_keys: ['image', 'label']
  loader:
    shuffle: True
    batch_size_per_card: 4
    drop_last: False
    num_workers: 4

Eval:
  dataset:
    name: LMDBDataSet
    data_dir: C:/Users/alstj/Desktop/TaeHwa/PaddleOCR/dataset/val_lmdb # í…ŒìŠ¤íŠ¸ìš© LMDB ë°ì´í„°ì…‹ ê²½ë¡œ
    label_file_path: C:/Users/alstj/Desktop/TaeHwa/PaddleOCR/dataset/val.txt
    transforms:
      - DecodeImage:
          img_mode: BGR
      - CTCLabelEncode:
          max_text_length: 25
      - RecResizeImg:
          image_shape: [3, 128, 640]  #  í•™ìŠµí•  ë•Œ í¬ê¸°ì™€ ì¼ì¹˜í•˜ê²Œ ìˆ˜ì •
      - KeepKeys:
          keep_keys: ['image', 'label']
  loader:
    shuffle: False
    drop_last: False
    batch_size_per_card: 16
    num_workers: 4

```

**ì‹¤í–‰ë°©ë²•(í•™ìŠµì‹œí‚¤ê¸°)**

```java
python tools/train.py -c configs/rec/korean_PP-OCRv3_rec_train.yml
```

ì²˜ìŒì— í•™ìŠµ í• ë•Œ 64 X 256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì§• í–ˆë”ë‹ˆ ì‚¬ì§„ì´ ì°Œê·¸ëŸ¬ì§€ëŠ” ì´ìŠˆê°€ ìƒê²¨ì„œ 

128X640 ìœ¼ë¡œ ë°”ê¿¨ë‹¤

**test.py**
```pytho
import cv2
import numpy as np
from paddleocr import PaddleOCR, draw_ocr
from PIL import Image


def resize_with_padding(image, target_size=(640, 128)):
    """
    ì›ë³¸ ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ target_size (width, height)ë¡œ ë³€í™˜ (íŒ¨ë”© ì¶”ê°€)
    """
    old_size = image.size  # (width, height)
    ratio = min(target_size[0] / old_size[0], target_size[1] / old_size[1])
    new_size = tuple([int(x * ratio) for x in old_size])
    img_resized = image.resize(new_size, Image.LANCZOS)

    new_img = Image.new("RGB", target_size, (255, 255, 255))
    paste_x = (target_size[0] - new_size[0]) // 2
    paste_y = (target_size[1] - new_size[1]) // 2
    new_img.paste(img_resized, (paste_x, paste_y))
    return new_img


def enhance_image(image):
    """
    ì´ë¯¸ì§€ ëŒ€ë¹„ ì¦ê°€ ë° ì„ ëª…í™” (ì ì‘í˜• ì´ì§„í™”ë¥¼ ì‚¬ìš©)
    """
    img = np.array(image)
    # 1ï¸âƒ£ ëŒ€ë¹„ ì¦ê°€: CLAHE ì ìš© (clipLimit=3.5)
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.5, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

    # 2ï¸âƒ£ í…ìŠ¤íŠ¸ ê°•ì¡°: ì ì‘í˜• ì´ì§„í™”
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    # OTSU ì´ì§„í™”ë¡œ ì„ê³„ê°’ ê²°ì •
    _, img_bin = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    # ë°°ê²½ ë°˜ì „: ì¼ë°˜ì ìœ¼ë¡œ í° ë°°ê²½, ê²€ì€ ê¸€ì”¨ë¥¼ ê°€ì •
    img_bin = cv2.bitwise_not(img_bin)

    return Image.fromarray(img_bin)


# í•™ìŠµëœ ëª¨ë¸ì— ë§ê²Œ OCR ì„¤ì • (í•™ìŠµ configì— ë”°ë¼ rec_image_shape="3,128,640", max_text_length:50 ë“±ìœ¼ë¡œ í•™ìŠµí–ˆë‹¤ê³  ê°€ì •)
ocr = PaddleOCR(
    use_angle_cls=True,
    lang='korean',
    det_model_dir='./output/det_korean',
    rec_model_dir='./output/rec_korean/latest',  # ìµœì‹  í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš© (Inference ëª¨ë¸ ë³€í™˜ í›„ ì‚¬ìš© ê°€ëŠ¥)
    rec_algorithm='SVTR_LCNet',
    rec_image_shape="3,128,640",  # í•™ìŠµ ì„¤ì •ê³¼ ë™ì¼í•˜ê²Œ
    rec_char_dict_path="ppocr/utils/dict/korean_dict.txt",
    use_space_char=True,
    drop_score=0.0001,
    pretrained_model="",  # pretrained_model ì˜µì…˜ì€ inference ëª¨ë¸ ë³€í™˜ í›„ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ ë¹„ì›Œë‘ê¸°
)

# ì›ë³¸ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
img_path = "dataset/train_images/image1.jpg"  # í•™ìŠµ configì˜ infer_img ê²½ë¡œ
img = Image.open(img_path)

# í•„ìš”ì‹œ ì‘ì€ ì´ë¯¸ì§€ë¼ë©´ ì—…ìŠ¤ì¼€ì¼ (ì—¬ê¸°ì„œëŠ” ê·¸ëŒ€ë¡œ ì§„í–‰)
if img.size[0] < 640 or img.size[1] < 128:
    scale = max(640 // img.size[0], 128 // img.size[1])
    img = img.resize((img.size[0] * scale, img.size[1] * scale), Image.LANCZOS)
    print(f"Image upscaled to: {img.size}")

# ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 640x128ë¡œ ë§ì¶”ê¸° (íŒ¨ë”© ì ìš©)
img_resized = resize_with_padding(img, target_size=(640, 128))
# ì „ì²˜ë¦¬: ëŒ€ë¹„ ê°•í™” ë° ì´ì§„í™” ì ìš©
img_processed = enhance_image(img_resized)

# ì €ì¥ (ë””ë²„ê¹…ìš©)
enhanced_img_path = "dataset/train_images/enhanced_image1.jpg"
img_processed.save(enhanced_img_path)
print(f"Processed image saved at: {enhanced_img_path}")

# OCR ì‹¤í–‰
result = ocr.ocr(enhanced_img_path, cls=True)

# OCR ê²°ê³¼ í™•ì¸
if result and result[0]:
    print("Detected Text Results:")
    for line in result[0]:
        print(f"Text: {line[1][0]} | Confidence: {line[1][1]}")

    # ê°ì§€ëœ ë°•ìŠ¤ ì‹œê°í™” (OpenCV ì´ë¯¸ì§€ ì‚¬ìš©)
    img_cv = cv2.imread(enhanced_img_path)
    boxes = [entry[0] for entry in result[0]]
    txts = [entry[1][0] for entry in result[0]]
    scores = [entry[1][1] for entry in result[0]]
    result_img = draw_ocr(img_cv, boxes, txts, scores, font_path="ppocr/utils/dict/korean_dict.txt")
    result_img = Image.fromarray(result_img)
    debug_image_path = "output/result_image.jpg"
    result_img.save(debug_image_path)
    print(f"Result image saved at: {debug_image_path}")
else:
    print("No text detected!")
```

### +ì¶”ê°€ ì‚¬í•­
í•™ìŠµë°ì´í„°ê°€ ë¶€ì¡± í–ˆìœ¼ë¯€ë¡œ ì¶”ê°€ì ì¸ í•™ìŠµë°ì´í„° ìƒì„±ì´ ë¶ˆê°€í”¼í–ˆë‹¤ ë”°ë¼ì„œ
```python
import cv2
import numpy as np
import random
from PIL import Image


image = Image.open('C:/Users/alstj/Desktop/image1.jpg')
image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)


def apply_augmentation(image_cv):
    augmented_image = image_cv.copy()

    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
    if random.random() < 0.5:
        blur_limit = random.randint(3, 7)
        # blur_limitì´ ì§ìˆ˜ì¼ ê²½ìš° í™€ìˆ˜ë¡œ ë³€ê²½
        if blur_limit % 2 == 0:
            blur_limit += 1
        augmented_image = cv2.GaussianBlur(augmented_image, (blur_limit, blur_limit), 0)

    # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ
    if random.random() < 0.5:
        noise_var = random.uniform(10.0, 50.0)
        gauss_noise = np.random.normal(0, noise_var, augmented_image.shape).astype(np.uint8)
        augmented_image = cv2.add(augmented_image, gauss_noise)


    if random.random() < 0.7:
        rows, cols, _ = augmented_image.shape
        shift_x = random.uniform(-0.1, 0.1) * cols
        shift_y = random.uniform(-0.1, 0.1) * rows
        scale = random.uniform(0.9, 1.1)
        rotation = random.randint(-15, 15)

        # ì´ë™ í–‰ë ¬
        M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])
        augmented_image = cv2.warpAffine(augmented_image, M, (cols, rows))

        # íšŒì „ ë° í¬ê¸° ì¡°ì •
        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation, scale)
        augmented_image = cv2.warpAffine(augmented_image, M, (cols, rows))

    if random.random() < 0.5:
        distort_limit = random.uniform(0.05, 0.1)
        augmented_image = cv2.resize(augmented_image, None, fx=1 + distort_limit, fy=1 + distort_limit)

    # ë°ê¸° ë° ëŒ€ë¹„ ë³€í™”
    if random.random() < 0.5:
        brightness = random.uniform(-0.2, 0.2)
        contrast = random.uniform(-0.2, 0.2)
        augmented_image = cv2.convertScaleAbs(augmented_image, alpha=1 + contrast, beta=brightness * 255)

    return augmented_image


# ì¦ê°•ëœ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
augmented_images = []
num_samples = 5  # ìƒì„±í•  ë°ì´í„° ê°œìˆ˜

for i in range(num_samples):
    augmented = apply_augmentation(image_cv)
    output_aug_path = f"C:/Users/alstj/Desktop/data/image1_aug_{i}.jpg"
    cv2.imwrite(output_aug_path, augmented)
    augmented_images.append(output_aug_path)

# ìƒì„±ëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜
augmented_images
```
ë°ì´í„° ì¦ê°•ì„ í†µí•´ í•™ìŠµí•  ë°ì´í„°ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ë§Œë“¤ì—ˆë‹¤<br><br><br>

ì´ë¯¸ì§€ ìì²´ë¡œëŠ” í•™ìŠµì´ ë¶ˆê°€ëŠ¥ í•˜ë‹¤ ë”°ë¼ì„œ ì´ë¯¸ì§€ë¥¼ .mdbí˜•íƒœë¡œ ë§Œë“¤ì–´ ì¤˜ì•¼í•˜ëŠ”ë°
ì´ ë–„,
```python
import os
import lmdb
import cv2
import numpy as np

def check_image_is_valid(image_path):
    """ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    try:
        img = cv2.imread(image_path)
        if img is None:
            return False
        return True
    except:
        return False

def writeCache(env, cache):
    """LMDBì— ë°ì´í„° ì €ì¥"""
    with env.begin(write=True) as txn:
        for k, v in cache.items():
            txn.put(k.encode(), v)

def createDataset(input_path, output_path, map_size=10**9):
    """LMDB ë°ì´í„°ì…‹ ìƒì„±"""
    os.makedirs(output_path, exist_ok=True)
    env = lmdb.open(output_path, map_size=map_size)

    with open(input_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    cache = {}
    cnt = 1

    for line in lines:
        line = line.strip()
        if not line:
            continue  # ë¹ˆ ì¤„ ìŠ¤í‚µ

        parts = line.split(maxsplit=1)  # ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ 1íšŒë§Œ split (ì²« ë²ˆì§¸ ê°’: ì´ë¯¸ì§€ ê²½ë¡œ, ë‚˜ë¨¸ì§€: ë¼ë²¨)
        if len(parts) < 2:
            print(f"âš ï¸ ì˜ëª»ëœ í˜•ì‹: {line}")
            continue

        img_path, label = parts  # ì²« ë²ˆì§¸ ê°’ì´ ì´ë¯¸ì§€ ê²½ë¡œ, ë‘ ë²ˆì§¸ ê°’ì´ ë¼ë²¨

        if not os.path.exists(img_path) or not check_image_is_valid(img_path):
            print(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {img_path}")
            continue

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì¸ì½”ë”© (ë°”ì´ë„ˆë¦¬ í˜•íƒœ)
        img = cv2.imread(img_path)
        _, img_encoded = cv2.imencode('.jpg', img)
        img_bin = img_encoded.tobytes()

        image_key = f'image-{cnt:09d}'
        label_key = f'label-{cnt:09d}'

        cache[image_key] = img_bin  # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ LMDBì— ì €ì¥
        cache[label_key] = label.encode()  # ë¬¸ìì—´ì„ ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥

        if cnt % 1000 == 0:
            writeCache(env, cache)
            cache = {}
            print(f'âœ… {cnt}ê°œì˜ ë°ì´í„° ë³€í™˜ ì™„ë£Œ')

        cnt += 1

    writeCache(env, cache)

    with env.begin(write=True) as txn:
        txn.put("num-samples".encode(), str(cnt - 1).encode())

    print(f"ğŸ‰ ì´ {cnt - 1}ê°œì˜ ë°ì´í„°ê°€ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    input_path = "C:/data/label.txt"  # label.txt íŒŒì¼ (ì´ë¯¸ì§€ ê²½ë¡œ + ë¼ë²¨ ì •ë³´)
    output_path = "C:/data/lmdb"  # LMDB ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ

    createDataset(input_path, output_path)
```
ìœ„ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“¤ì—ˆë‹¤.
